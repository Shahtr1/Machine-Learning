{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c5d2722-ff49-45b9-94f4-b70b0bddbafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "block_size = 8\n",
    "batch_size = 32\n",
    "max_iters = 100000\n",
    "eval_iters = 250\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Store loss values for plotting\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "iterations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf9d14d-a503-404b-aabb-9db9139f6e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\ufeff']\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "with open('wizard_of_oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "chars = sorted(set(text))\n",
    "print(chars)\n",
    "print(len(chars))\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdc5700c-d177-4df0-9b11-e0e7a6059a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
      "         1, 47, 33, 50, 25, 42, 28,  1, 33, 38,  1, 39, 50,  0,  0,  1,  1, 26,\n",
      "        49,  0,  0,  1,  1, 36, 11,  1, 30, 42, 25, 38, 35,  1, 26, 25, 45, 37,\n",
      "         0,  0,  1,  1, 25, 45, 44, 32, 39, 42,  1, 39, 30,  1, 44, 32, 29,  1,\n",
      "        47, 33, 50, 25, 42, 28,  1, 39, 30,  1, 39, 50,  9,  1, 44, 32, 29,  1,\n",
      "        36, 25, 38, 28,  1, 39, 30,  1, 39, 50])\n",
      "232309\n"
     ]
    }
   ],
   "source": [
    "string_to_int = {ch:i for i,ch in enumerate(chars)}\n",
    "int_to_string = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data[:100])\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "tensor([[54, 62, 57, 58, 57,  1, 66, 54],\n",
      "        [72, 56, 71, 54, 69, 58,  1, 68],\n",
      "        [73, 61, 58,  1, 67, 54, 73, 74],\n",
      "        [ 1, 55, 58, 62, 67, 60,  0, 69],\n",
      "        [60, 61, 55, 68, 71, 62, 67, 60],\n",
      "        [58, 69, 54, 71, 58, 57,  1, 73],\n",
      "        [62, 67, 57,  1, 61, 62, 66,  1],\n",
      "        [55, 68, 57, 78,  1, 67, 58, 71],\n",
      "        [64,  1, 73, 61, 58,  1, 71, 58],\n",
      "        [54, 67, 57,  1, 73, 61, 58, 71],\n",
      "        [65, 58, 69, 61, 54, 67, 73,  9],\n",
      "        [ 0, 55, 54, 56, 64,  1, 54, 60],\n",
      "        [ 1, 66, 74, 72, 73,  1, 59, 58],\n",
      "        [ 1, 54,  0, 55, 74, 67, 56, 61],\n",
      "        [57,  1, 74, 69, 68, 67,  0, 61],\n",
      "        [58, 58, 66, 58, 57,  1, 72, 73],\n",
      "        [25, 28, 39,  9,  1, 13, 21, 12],\n",
      "        [68, 73, 61, 78,  1, 56, 54, 73],\n",
      "        [71, 54, 55, 62, 54, 67,  1, 38],\n",
      "        [65, 68, 74, 57, 72,  9,  1, 54],\n",
      "        [ 1, 73, 61, 58, 66,  1, 76, 58],\n",
      "        [ 1, 78, 68, 74,  1, 56, 54, 66],\n",
      "        [73, 11,  1, 44, 61, 58, 71, 58],\n",
      "        [ 1, 54, 67, 57,  1, 60, 71, 68],\n",
      "        [ 1, 69, 58, 68, 69, 65, 58,  1],\n",
      "        [54, 73,  1, 56, 65, 68, 74, 57],\n",
      "        [ 0,  0,  3, 37, 78,  1, 67, 54],\n",
      "        [54, 55, 68, 74, 73,  1, 62, 73],\n",
      "        [24,  3,  0,  0,  3, 39, 59,  1],\n",
      "        [54, 67, 57,  1, 69, 74, 73,  1],\n",
      "        [73, 61, 58,  1, 59, 65, 54, 66],\n",
      "        [72, 73, 71, 54, 62, 60, 61, 73]], device='cuda:0')\n",
      "targets:\n",
      "tensor([[62, 57, 58, 57,  1, 66, 54, 67],\n",
      "        [56, 71, 54, 69, 58,  1, 68, 74],\n",
      "        [61, 58,  1, 67, 54, 73, 74, 71],\n",
      "        [55, 58, 62, 67, 60,  0, 69, 71],\n",
      "        [61, 55, 68, 71, 62, 67, 60,  1],\n",
      "        [69, 54, 71, 58, 57,  1, 73, 68],\n",
      "        [67, 57,  1, 61, 62, 66,  1, 62],\n",
      "        [68, 57, 78,  1, 67, 58, 71, 75],\n",
      "        [ 1, 73, 61, 58,  1, 71, 58, 62],\n",
      "        [67, 57,  1, 73, 61, 58, 71, 58],\n",
      "        [58, 69, 61, 54, 67, 73,  9,  1],\n",
      "        [55, 54, 56, 64,  1, 54, 60, 54],\n",
      "        [66, 74, 72, 73,  1, 59, 58, 58],\n",
      "        [54,  0, 55, 74, 67, 56, 61,  1],\n",
      "        [ 1, 74, 69, 68, 67,  0, 61, 62],\n",
      "        [58, 66, 58, 57,  1, 72, 73, 62],\n",
      "        [28, 39,  9,  1, 13, 21, 12, 20],\n",
      "        [73, 61, 78,  1, 56, 54, 73, 56],\n",
      "        [54, 55, 62, 54, 67,  1, 38, 62],\n",
      "        [68, 74, 57, 72,  9,  1, 54, 67],\n",
      "        [73, 61, 58, 66,  1, 76, 58, 65],\n",
      "        [78, 68, 74,  1, 56, 54, 66, 58],\n",
      "        [11,  1, 44, 61, 58, 71, 58,  1],\n",
      "        [54, 67, 57,  1, 60, 71, 68, 75],\n",
      "        [69, 58, 68, 69, 65, 58,  1, 61],\n",
      "        [73,  1, 56, 65, 68, 74, 57,  1],\n",
      "        [ 0,  3, 37, 78,  1, 67, 54, 66],\n",
      "        [55, 68, 74, 73,  1, 62, 73,  9],\n",
      "        [ 3,  0,  0,  3, 39, 59,  1, 56],\n",
      "        [67, 57,  1, 69, 74, 73,  1, 68],\n",
      "        [61, 58,  1, 59, 65, 54, 66, 58],\n",
      "        [73, 71, 54, 62, 60, 61, 73, 76]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n = int(0.8 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i : i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1 : i+block_size+1] for i in ix])\n",
    "    x,y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('train')\n",
    "print('inputs:')\n",
    "print(x)\n",
    "print('targets:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cccc350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91d95bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "V**H9LL8 JNpFw :ut(EeNI2A7i6yhXn0trh﻿AV*[E5v*L4f?-PZ)_SNlT;r8Em H4tdP_zTdE[r8 Jwzn.C(\n",
      "'LM&; nK*0hf0mLA997n'kmxh_1KlO2VrwGWmVW2zY[FLvD\"_rG&Rqd[JP﻿8-Wd'iT\"qFfgG,Lf﻿aQVYlngM7u8\"f'ql!Sf(JH!&eJ'DO)_1K]B5eqI1Ij2jNy.'v,ofPvLtT-WlB0fPZJ;y\"I&mdX_7Ucof0T]B2Q5VE5ZmX\"cm-Wg?mU**6dQdqFaGxRY[Sj;X,tRIH\n",
      "Tdq;L0C5Q]Q!jfc4DryvWdyiQHqw DreR*lgRs\"vnZZ]Kql:!&GWnjClSjYTvTxto8a8\"'??Ja4;,M!S7bP(c'eEl*foWvWZ1SxJ,by-hz6Y2:[X;oE.2FNsy9.0C3Z6I)EalR\":S(﻿U1)9_fidE F(c4\n",
      "E Ly-6h]k)018* Dj,RLGF]ZYtzHqHp.'J6JQfW(VSbssI)\"cXiltAg&y4\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguaageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        logits = self.token_embedding_table(index)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            batch_size, time_steps, vocab_size = logits.shape\n",
    "            logits = logits.view(batch_size * time_steps, vocab_size)\n",
    "            targets = targets.view(batch_size * time_steps)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self.forward(index) # self(index), will call self.forward automatically\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            index_next = torch.multinomial(probs, num_samples=1)\n",
    "            index = torch.cat((index, index_next), dim=1)\n",
    "        return index\n",
    "    \n",
    "model = BigramLanguaageModel(vocab_size)\n",
    "m = model.to(device)\n",
    "\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1cceb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to log output (append to file and print to console)\n",
    "def log_output(message):\n",
    "    with open(\"logs/training_log.txt\", \"a\") as log_file:  # \"a\" for append mode\n",
    "        print(message)  # Print to console\n",
    "        log_file.write(message + \"\\n\")  # Append to file\n",
    "\n",
    "# Function to clear the log file (delete its contents)\n",
    "def clear_log_file():\n",
    "    open(\"logs/training_log.txt\", \"w\").close()  # Open in \"w\" mode to overwrite with an empty file\n",
    "    print(\"Log file cleared!\")  # Print confirmation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cedd415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file cleared!\n",
      "step 0: train loss 4.8429, val loss 4.8659\n",
      "step 250: train loss 4.8095, val loss 4.8307\n",
      "step 500: train loss 4.7833, val loss 4.8063\n",
      "step 750: train loss 4.7473, val loss 4.7664\n",
      "step 1000: train loss 4.7182, val loss 4.7453\n",
      "step 1250: train loss 4.6912, val loss 4.7106\n",
      "step 1500: train loss 4.6635, val loss 4.6801\n",
      "step 1750: train loss 4.6336, val loss 4.6509\n",
      "step 2000: train loss 4.5962, val loss 4.6264\n",
      "step 2250: train loss 4.5715, val loss 4.5905\n",
      "step 2500: train loss 4.5414, val loss 4.5607\n",
      "step 2750: train loss 4.5101, val loss 4.5278\n",
      "step 3000: train loss 4.4813, val loss 4.5072\n",
      "step 3250: train loss 4.4527, val loss 4.4712\n",
      "step 3500: train loss 4.4260, val loss 4.4500\n",
      "step 3750: train loss 4.3999, val loss 4.4249\n",
      "step 4000: train loss 4.3701, val loss 4.3902\n",
      "step 4250: train loss 4.3362, val loss 4.3676\n",
      "step 4500: train loss 4.3111, val loss 4.3369\n",
      "step 4750: train loss 4.2873, val loss 4.3134\n",
      "step 5000: train loss 4.2595, val loss 4.2845\n",
      "step 5250: train loss 4.2274, val loss 4.2581\n",
      "step 5500: train loss 4.2047, val loss 4.2305\n",
      "step 5750: train loss 4.1801, val loss 4.2102\n",
      "step 6000: train loss 4.1498, val loss 4.1765\n",
      "step 6250: train loss 4.1262, val loss 4.1514\n",
      "step 6500: train loss 4.1039, val loss 4.1253\n",
      "step 6750: train loss 4.0752, val loss 4.1008\n",
      "step 7000: train loss 4.0448, val loss 4.0786\n",
      "step 7250: train loss 4.0300, val loss 4.0483\n",
      "step 7500: train loss 4.0011, val loss 4.0204\n",
      "step 7750: train loss 3.9692, val loss 4.0060\n",
      "step 8000: train loss 3.9509, val loss 3.9822\n",
      "step 8250: train loss 3.9265, val loss 3.9559\n",
      "step 8500: train loss 3.9030, val loss 3.9330\n",
      "step 8750: train loss 3.8751, val loss 3.9083\n",
      "step 9000: train loss 3.8519, val loss 3.8855\n",
      "step 9250: train loss 3.8249, val loss 3.8609\n",
      "step 9500: train loss 3.8017, val loss 3.8342\n",
      "step 9750: train loss 3.7832, val loss 3.8194\n",
      "step 10000: train loss 3.7685, val loss 3.8016\n",
      "step 10250: train loss 3.7434, val loss 3.7685\n",
      "step 10500: train loss 3.7166, val loss 3.7488\n",
      "step 10750: train loss 3.6931, val loss 3.7302\n",
      "step 11000: train loss 3.6773, val loss 3.7063\n",
      "step 11250: train loss 3.6556, val loss 3.6889\n",
      "step 11500: train loss 3.6400, val loss 3.6648\n",
      "step 11750: train loss 3.6225, val loss 3.6453\n",
      "step 12000: train loss 3.5968, val loss 3.6243\n",
      "step 12250: train loss 3.5838, val loss 3.6087\n",
      "step 12500: train loss 3.5519, val loss 3.5822\n",
      "step 12750: train loss 3.5328, val loss 3.5646\n",
      "step 13000: train loss 3.5232, val loss 3.5549\n",
      "step 13250: train loss 3.4926, val loss 3.5249\n",
      "step 13500: train loss 3.4839, val loss 3.5120\n",
      "step 13750: train loss 3.4581, val loss 3.4997\n",
      "step 14000: train loss 3.4404, val loss 3.4755\n",
      "step 14250: train loss 3.4205, val loss 3.4677\n",
      "step 14500: train loss 3.3988, val loss 3.4300\n",
      "step 14750: train loss 3.3897, val loss 3.4126\n",
      "step 15000: train loss 3.3667, val loss 3.3979\n",
      "step 15250: train loss 3.3514, val loss 3.3831\n",
      "step 15500: train loss 3.3356, val loss 3.3732\n",
      "step 15750: train loss 3.3110, val loss 3.3491\n",
      "step 16000: train loss 3.3002, val loss 3.3365\n",
      "step 16250: train loss 3.2761, val loss 3.3288\n",
      "step 16500: train loss 3.2730, val loss 3.3056\n",
      "step 16750: train loss 3.2491, val loss 3.2908\n",
      "step 17000: train loss 3.2415, val loss 3.2767\n",
      "step 17250: train loss 3.2201, val loss 3.2521\n",
      "step 17500: train loss 3.2086, val loss 3.2450\n",
      "step 17750: train loss 3.1972, val loss 3.2375\n",
      "step 18000: train loss 3.1738, val loss 3.2146\n",
      "step 18250: train loss 3.1621, val loss 3.1938\n",
      "step 18500: train loss 3.1565, val loss 3.1777\n",
      "step 18750: train loss 3.1319, val loss 3.1618\n",
      "step 19000: train loss 3.1217, val loss 3.1632\n",
      "step 19250: train loss 3.1092, val loss 3.1455\n",
      "step 19500: train loss 3.0998, val loss 3.1385\n",
      "step 19750: train loss 3.0928, val loss 3.1194\n",
      "step 20000: train loss 3.0712, val loss 3.1120\n",
      "step 20250: train loss 3.0629, val loss 3.0875\n",
      "step 20500: train loss 3.0429, val loss 3.0830\n",
      "step 20750: train loss 3.0297, val loss 3.0719\n",
      "step 21000: train loss 3.0221, val loss 3.0532\n",
      "step 21250: train loss 3.0102, val loss 3.0447\n",
      "step 21500: train loss 2.9972, val loss 3.0419\n",
      "step 21750: train loss 2.9872, val loss 3.0231\n",
      "step 22000: train loss 2.9813, val loss 3.0113\n",
      "step 22250: train loss 2.9630, val loss 3.0057\n",
      "step 22500: train loss 2.9609, val loss 2.9957\n",
      "step 22750: train loss 2.9468, val loss 2.9823\n",
      "step 23000: train loss 2.9317, val loss 2.9677\n",
      "step 23250: train loss 2.9209, val loss 2.9635\n",
      "step 23500: train loss 2.9149, val loss 2.9554\n",
      "step 23750: train loss 2.9103, val loss 2.9541\n",
      "step 24000: train loss 2.8977, val loss 2.9350\n",
      "step 24250: train loss 2.8965, val loss 2.9240\n",
      "step 24500: train loss 2.8838, val loss 2.9185\n",
      "step 24750: train loss 2.8598, val loss 2.9071\n",
      "step 25000: train loss 2.8560, val loss 2.8980\n",
      "step 25250: train loss 2.8456, val loss 2.8904\n",
      "step 25500: train loss 2.8450, val loss 2.8916\n",
      "step 25750: train loss 2.8357, val loss 2.8774\n",
      "step 26000: train loss 2.8219, val loss 2.8686\n",
      "step 26250: train loss 2.8200, val loss 2.8555\n",
      "step 26500: train loss 2.8089, val loss 2.8467\n",
      "step 26750: train loss 2.8020, val loss 2.8343\n",
      "step 27000: train loss 2.7909, val loss 2.8464\n",
      "step 27250: train loss 2.7866, val loss 2.8270\n",
      "step 27500: train loss 2.7837, val loss 2.8235\n",
      "step 27750: train loss 2.7736, val loss 2.8239\n",
      "step 28000: train loss 2.7628, val loss 2.8039\n",
      "step 28250: train loss 2.7543, val loss 2.8088\n",
      "step 28500: train loss 2.7571, val loss 2.7925\n",
      "step 28750: train loss 2.7463, val loss 2.8049\n",
      "step 29000: train loss 2.7376, val loss 2.7773\n",
      "step 29250: train loss 2.7345, val loss 2.7694\n",
      "step 29500: train loss 2.7180, val loss 2.7601\n",
      "step 29750: train loss 2.7217, val loss 2.7654\n",
      "step 30000: train loss 2.7165, val loss 2.7563\n",
      "step 30250: train loss 2.7075, val loss 2.7550\n",
      "step 30500: train loss 2.6999, val loss 2.7437\n",
      "step 30750: train loss 2.7039, val loss 2.7397\n",
      "step 31000: train loss 2.6962, val loss 2.7298\n",
      "step 31250: train loss 2.6902, val loss 2.7266\n",
      "step 31500: train loss 2.6789, val loss 2.7334\n",
      "step 31750: train loss 2.6746, val loss 2.7304\n",
      "step 32000: train loss 2.6692, val loss 2.7161\n",
      "step 32250: train loss 2.6653, val loss 2.7206\n",
      "step 32500: train loss 2.6645, val loss 2.7100\n",
      "step 32750: train loss 2.6573, val loss 2.7042\n",
      "step 33000: train loss 2.6498, val loss 2.6903\n",
      "step 33250: train loss 2.6522, val loss 2.6913\n",
      "step 33500: train loss 2.6362, val loss 2.6916\n",
      "step 33750: train loss 2.6501, val loss 2.6903\n",
      "step 34000: train loss 2.6345, val loss 2.6818\n",
      "step 34250: train loss 2.6313, val loss 2.6719\n",
      "step 34500: train loss 2.6285, val loss 2.6713\n",
      "step 34750: train loss 2.6221, val loss 2.6609\n",
      "step 35000: train loss 2.6154, val loss 2.6624\n",
      "step 35250: train loss 2.6149, val loss 2.6473\n",
      "step 35500: train loss 2.6114, val loss 2.6584\n",
      "step 35750: train loss 2.6181, val loss 2.6493\n",
      "step 36000: train loss 2.6094, val loss 2.6518\n",
      "step 36250: train loss 2.6143, val loss 2.6431\n",
      "step 36500: train loss 2.5985, val loss 2.6460\n",
      "step 36750: train loss 2.5992, val loss 2.6355\n",
      "step 37000: train loss 2.5936, val loss 2.6400\n",
      "step 37250: train loss 2.5901, val loss 2.6395\n",
      "step 37500: train loss 2.5898, val loss 2.6247\n",
      "step 37750: train loss 2.5802, val loss 2.6295\n",
      "step 38000: train loss 2.5824, val loss 2.6214\n",
      "step 38250: train loss 2.5804, val loss 2.6246\n",
      "step 38500: train loss 2.5723, val loss 2.6133\n",
      "step 38750: train loss 2.5778, val loss 2.6140\n",
      "step 39000: train loss 2.5686, val loss 2.6104\n",
      "step 39250: train loss 2.5640, val loss 2.6195\n",
      "step 39500: train loss 2.5635, val loss 2.6095\n",
      "step 39750: train loss 2.5671, val loss 2.6065\n",
      "step 40000: train loss 2.5643, val loss 2.6018\n",
      "step 40250: train loss 2.5594, val loss 2.5995\n",
      "step 40500: train loss 2.5535, val loss 2.6116\n",
      "step 40750: train loss 2.5517, val loss 2.5963\n",
      "step 41000: train loss 2.5473, val loss 2.6022\n",
      "step 41250: train loss 2.5506, val loss 2.5906\n",
      "step 41500: train loss 2.5444, val loss 2.5944\n",
      "step 41750: train loss 2.5439, val loss 2.5875\n",
      "step 42000: train loss 2.5378, val loss 2.5912\n",
      "step 42250: train loss 2.5361, val loss 2.5835\n",
      "step 42500: train loss 2.5400, val loss 2.5830\n",
      "step 42750: train loss 2.5314, val loss 2.5734\n",
      "step 43000: train loss 2.5402, val loss 2.5804\n",
      "step 43250: train loss 2.5391, val loss 2.5771\n",
      "step 43500: train loss 2.5380, val loss 2.5760\n",
      "step 43750: train loss 2.5269, val loss 2.5721\n",
      "step 44000: train loss 2.5265, val loss 2.5715\n",
      "step 44250: train loss 2.5258, val loss 2.5648\n",
      "step 44500: train loss 2.5217, val loss 2.5788\n",
      "step 44750: train loss 2.5240, val loss 2.5716\n",
      "step 45000: train loss 2.5250, val loss 2.5721\n",
      "step 45250: train loss 2.5251, val loss 2.5631\n",
      "step 45500: train loss 2.5167, val loss 2.5659\n",
      "step 45750: train loss 2.5184, val loss 2.5581\n",
      "step 46000: train loss 2.5056, val loss 2.5629\n",
      "step 46250: train loss 2.5177, val loss 2.5648\n",
      "step 46500: train loss 2.5067, val loss 2.5512\n",
      "step 46750: train loss 2.5081, val loss 2.5574\n",
      "step 47000: train loss 2.5119, val loss 2.5627\n",
      "step 47250: train loss 2.5070, val loss 2.5519\n",
      "step 47500: train loss 2.5132, val loss 2.5574\n",
      "step 47750: train loss 2.5098, val loss 2.5557\n",
      "step 48000: train loss 2.5081, val loss 2.5501\n",
      "step 48250: train loss 2.5043, val loss 2.5521\n",
      "step 48500: train loss 2.5061, val loss 2.5439\n",
      "step 48750: train loss 2.5043, val loss 2.5414\n",
      "step 49000: train loss 2.5013, val loss 2.5335\n",
      "step 49250: train loss 2.4936, val loss 2.5434\n",
      "step 49500: train loss 2.4944, val loss 2.5342\n",
      "step 49750: train loss 2.4954, val loss 2.5426\n",
      "step 50000: train loss 2.4956, val loss 2.5325\n",
      "step 50250: train loss 2.4959, val loss 2.5401\n",
      "step 50500: train loss 2.4926, val loss 2.5391\n",
      "step 50750: train loss 2.4908, val loss 2.5408\n",
      "step 51000: train loss 2.4900, val loss 2.5336\n",
      "step 51250: train loss 2.4862, val loss 2.5384\n",
      "step 51500: train loss 2.4870, val loss 2.5384\n",
      "step 51750: train loss 2.4879, val loss 2.5346\n",
      "step 52000: train loss 2.4887, val loss 2.5326\n",
      "step 52250: train loss 2.4921, val loss 2.5305\n",
      "step 52500: train loss 2.4836, val loss 2.5280\n",
      "step 52750: train loss 2.4808, val loss 2.5276\n",
      "step 53000: train loss 2.4773, val loss 2.5332\n",
      "step 53250: train loss 2.4821, val loss 2.5270\n",
      "step 53500: train loss 2.4855, val loss 2.5337\n",
      "step 53750: train loss 2.4834, val loss 2.5237\n",
      "step 54000: train loss 2.4806, val loss 2.5307\n",
      "step 54250: train loss 2.4842, val loss 2.5156\n",
      "step 54500: train loss 2.4722, val loss 2.5214\n",
      "step 54750: train loss 2.4743, val loss 2.5246\n",
      "step 55000: train loss 2.4809, val loss 2.5159\n",
      "step 55250: train loss 2.4785, val loss 2.5236\n",
      "step 55500: train loss 2.4787, val loss 2.5230\n",
      "step 55750: train loss 2.4758, val loss 2.5157\n",
      "step 56000: train loss 2.4726, val loss 2.5278\n",
      "step 56250: train loss 2.4726, val loss 2.5202\n",
      "step 56500: train loss 2.4608, val loss 2.5116\n",
      "step 56750: train loss 2.4815, val loss 2.5138\n",
      "step 57000: train loss 2.4749, val loss 2.5243\n",
      "step 57250: train loss 2.4765, val loss 2.5217\n",
      "step 57500: train loss 2.4736, val loss 2.5115\n",
      "step 57750: train loss 2.4757, val loss 2.5118\n",
      "step 58000: train loss 2.4704, val loss 2.5178\n",
      "step 58250: train loss 2.4686, val loss 2.5208\n",
      "step 58500: train loss 2.4634, val loss 2.5083\n",
      "step 58750: train loss 2.4754, val loss 2.5067\n",
      "step 59000: train loss 2.4638, val loss 2.5105\n",
      "step 59250: train loss 2.4718, val loss 2.5190\n",
      "step 59500: train loss 2.4703, val loss 2.5086\n",
      "step 59750: train loss 2.4544, val loss 2.5065\n",
      "step 60000: train loss 2.4561, val loss 2.5130\n",
      "step 60250: train loss 2.4641, val loss 2.5017\n",
      "step 60500: train loss 2.4592, val loss 2.5215\n",
      "step 60750: train loss 2.4601, val loss 2.5098\n",
      "step 61000: train loss 2.4497, val loss 2.5027\n",
      "step 61250: train loss 2.4608, val loss 2.5099\n",
      "step 61500: train loss 2.4630, val loss 2.5118\n",
      "step 61750: train loss 2.4675, val loss 2.5129\n",
      "step 62000: train loss 2.4518, val loss 2.4995\n",
      "step 62250: train loss 2.4625, val loss 2.5058\n",
      "step 62500: train loss 2.4544, val loss 2.5087\n",
      "step 62750: train loss 2.4554, val loss 2.5078\n",
      "step 63000: train loss 2.4608, val loss 2.5033\n",
      "step 63250: train loss 2.4541, val loss 2.4982\n",
      "step 63500: train loss 2.4508, val loss 2.4997\n",
      "step 63750: train loss 2.4572, val loss 2.5011\n",
      "step 64000: train loss 2.4518, val loss 2.5025\n",
      "step 64250: train loss 2.4557, val loss 2.5069\n",
      "step 64500: train loss 2.4500, val loss 2.5018\n",
      "step 64750: train loss 2.4586, val loss 2.5098\n",
      "step 65000: train loss 2.4539, val loss 2.4939\n",
      "step 65250: train loss 2.4520, val loss 2.5075\n",
      "step 65500: train loss 2.4463, val loss 2.5030\n",
      "step 65750: train loss 2.4546, val loss 2.5093\n",
      "step 66000: train loss 2.4516, val loss 2.5066\n",
      "step 66250: train loss 2.4578, val loss 2.4984\n",
      "step 66500: train loss 2.4472, val loss 2.5035\n",
      "step 66750: train loss 2.4545, val loss 2.5054\n",
      "step 67000: train loss 2.4528, val loss 2.4897\n",
      "step 67250: train loss 2.4452, val loss 2.5055\n",
      "step 67500: train loss 2.4523, val loss 2.5044\n",
      "step 67750: train loss 2.4499, val loss 2.4955\n",
      "step 68000: train loss 2.4531, val loss 2.4992\n",
      "step 68250: train loss 2.4486, val loss 2.4985\n",
      "step 68500: train loss 2.4464, val loss 2.4964\n",
      "step 68750: train loss 2.4374, val loss 2.5013\n",
      "step 69000: train loss 2.4493, val loss 2.4804\n",
      "step 69250: train loss 2.4508, val loss 2.4989\n",
      "step 69500: train loss 2.4514, val loss 2.4942\n",
      "step 69750: train loss 2.4488, val loss 2.4837\n",
      "step 70000: train loss 2.4485, val loss 2.4959\n",
      "step 70250: train loss 2.4484, val loss 2.4979\n",
      "step 70500: train loss 2.4495, val loss 2.4936\n",
      "step 70750: train loss 2.4488, val loss 2.5015\n",
      "step 71000: train loss 2.4514, val loss 2.4902\n",
      "step 71250: train loss 2.4448, val loss 2.4914\n",
      "step 71500: train loss 2.4456, val loss 2.4921\n",
      "step 71750: train loss 2.4491, val loss 2.4941\n",
      "step 72000: train loss 2.4488, val loss 2.4862\n",
      "step 72250: train loss 2.4517, val loss 2.4851\n",
      "step 72500: train loss 2.4448, val loss 2.4875\n",
      "step 72750: train loss 2.4403, val loss 2.4909\n",
      "step 73000: train loss 2.4462, val loss 2.4924\n",
      "step 73250: train loss 2.4508, val loss 2.4852\n",
      "step 73500: train loss 2.4458, val loss 2.4956\n",
      "step 73750: train loss 2.4403, val loss 2.4899\n",
      "step 74000: train loss 2.4356, val loss 2.4977\n",
      "step 74250: train loss 2.4403, val loss 2.4894\n",
      "step 74500: train loss 2.4426, val loss 2.4860\n",
      "step 74750: train loss 2.4484, val loss 2.4871\n",
      "step 75000: train loss 2.4425, val loss 2.4907\n",
      "step 75250: train loss 2.4394, val loss 2.4815\n",
      "step 75500: train loss 2.4449, val loss 2.4876\n",
      "step 75750: train loss 2.4480, val loss 2.4841\n",
      "step 76000: train loss 2.4485, val loss 2.4924\n",
      "step 76250: train loss 2.4329, val loss 2.4898\n",
      "step 76500: train loss 2.4450, val loss 2.4858\n",
      "step 76750: train loss 2.4465, val loss 2.4890\n",
      "step 77000: train loss 2.4477, val loss 2.4850\n",
      "step 77250: train loss 2.4387, val loss 2.4896\n",
      "step 77500: train loss 2.4379, val loss 2.4937\n",
      "step 77750: train loss 2.4445, val loss 2.4882\n",
      "step 78000: train loss 2.4502, val loss 2.4870\n",
      "step 78250: train loss 2.4280, val loss 2.4896\n",
      "step 78500: train loss 2.4386, val loss 2.4828\n",
      "step 78750: train loss 2.4405, val loss 2.4800\n",
      "step 79000: train loss 2.4355, val loss 2.4916\n",
      "step 79250: train loss 2.4391, val loss 2.4897\n",
      "step 79500: train loss 2.4407, val loss 2.4852\n",
      "step 79750: train loss 2.4381, val loss 2.4891\n",
      "step 80000: train loss 2.4358, val loss 2.4901\n",
      "step 80250: train loss 2.4289, val loss 2.4878\n",
      "step 80500: train loss 2.4439, val loss 2.4947\n",
      "step 80750: train loss 2.4314, val loss 2.4845\n",
      "step 81000: train loss 2.4305, val loss 2.4832\n",
      "step 81250: train loss 2.4270, val loss 2.4859\n",
      "step 81500: train loss 2.4367, val loss 2.4917\n",
      "step 81750: train loss 2.4352, val loss 2.4998\n",
      "step 82000: train loss 2.4472, val loss 2.4861\n",
      "step 82250: train loss 2.4391, val loss 2.4804\n",
      "step 82500: train loss 2.4378, val loss 2.4819\n",
      "step 82750: train loss 2.4289, val loss 2.4835\n",
      "step 83000: train loss 2.4410, val loss 2.4775\n",
      "step 83250: train loss 2.4379, val loss 2.4880\n",
      "step 83500: train loss 2.4242, val loss 2.4825\n",
      "step 83750: train loss 2.4360, val loss 2.4793\n",
      "step 84000: train loss 2.4316, val loss 2.4903\n",
      "step 84250: train loss 2.4314, val loss 2.4875\n",
      "step 84500: train loss 2.4374, val loss 2.4869\n",
      "step 84750: train loss 2.4335, val loss 2.4903\n",
      "step 85000: train loss 2.4385, val loss 2.4830\n",
      "step 85250: train loss 2.4341, val loss 2.4826\n",
      "step 85500: train loss 2.4330, val loss 2.4888\n",
      "step 85750: train loss 2.4433, val loss 2.4720\n",
      "step 86000: train loss 2.4342, val loss 2.4722\n",
      "step 86250: train loss 2.4301, val loss 2.4855\n",
      "step 86500: train loss 2.4340, val loss 2.4819\n",
      "step 86750: train loss 2.4369, val loss 2.4865\n",
      "step 87000: train loss 2.4300, val loss 2.4909\n",
      "step 87250: train loss 2.4391, val loss 2.4785\n",
      "step 87500: train loss 2.4392, val loss 2.4812\n",
      "step 87750: train loss 2.4394, val loss 2.4762\n",
      "step 88000: train loss 2.4231, val loss 2.4802\n",
      "step 88250: train loss 2.4334, val loss 2.4833\n",
      "step 88500: train loss 2.4324, val loss 2.4879\n",
      "step 88750: train loss 2.4287, val loss 2.4779\n",
      "step 89000: train loss 2.4314, val loss 2.4896\n",
      "step 89250: train loss 2.4278, val loss 2.4777\n",
      "step 89500: train loss 2.4361, val loss 2.4793\n",
      "step 89750: train loss 2.4376, val loss 2.4824\n",
      "step 90000: train loss 2.4272, val loss 2.4848\n",
      "step 90250: train loss 2.4330, val loss 2.4880\n",
      "step 90500: train loss 2.4307, val loss 2.4815\n",
      "step 90750: train loss 2.4269, val loss 2.4778\n",
      "step 91000: train loss 2.4259, val loss 2.4977\n",
      "step 91250: train loss 2.4356, val loss 2.4928\n",
      "step 91500: train loss 2.4362, val loss 2.4779\n",
      "step 91750: train loss 2.4267, val loss 2.4851\n",
      "step 92000: train loss 2.4283, val loss 2.4845\n",
      "step 92250: train loss 2.4267, val loss 2.4881\n",
      "step 92500: train loss 2.4273, val loss 2.4772\n",
      "step 92750: train loss 2.4321, val loss 2.4749\n",
      "step 93000: train loss 2.4309, val loss 2.4805\n",
      "step 93250: train loss 2.4277, val loss 2.4778\n",
      "step 93500: train loss 2.4333, val loss 2.4873\n",
      "step 93750: train loss 2.4334, val loss 2.4849\n",
      "step 94000: train loss 2.4340, val loss 2.4819\n",
      "step 94250: train loss 2.4305, val loss 2.4833\n",
      "step 94500: train loss 2.4323, val loss 2.4876\n",
      "step 94750: train loss 2.4278, val loss 2.4826\n",
      "step 95000: train loss 2.4256, val loss 2.4719\n",
      "step 95250: train loss 2.4304, val loss 2.4758\n",
      "step 95500: train loss 2.4287, val loss 2.4778\n",
      "step 95750: train loss 2.4309, val loss 2.4840\n",
      "step 96000: train loss 2.4312, val loss 2.4822\n",
      "step 96250: train loss 2.4288, val loss 2.4726\n",
      "step 96500: train loss 2.4302, val loss 2.4869\n",
      "step 96750: train loss 2.4250, val loss 2.4797\n",
      "step 97000: train loss 2.4259, val loss 2.4642\n",
      "step 97250: train loss 2.4277, val loss 2.4736\n",
      "step 97500: train loss 2.4357, val loss 2.4790\n",
      "step 97750: train loss 2.4346, val loss 2.4806\n",
      "step 98000: train loss 2.4316, val loss 2.4910\n",
      "step 98250: train loss 2.4335, val loss 2.4769\n",
      "step 98500: train loss 2.4433, val loss 2.4778\n",
      "step 98750: train loss 2.4321, val loss 2.4888\n",
      "step 99000: train loss 2.4262, val loss 2.4819\n",
      "step 99250: train loss 2.4287, val loss 2.4626\n",
      "step 99500: train loss 2.4306, val loss 2.4770\n",
      "step 99750: train loss 2.4282, val loss 2.4703\n",
      "2.45811128616333\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "clear_log_file()\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        train_losses.append(losses['train'].item())\n",
    "        val_losses.append(losses['val'].item())\n",
    "        iterations.append(iter)  # Store the current step\n",
    "        log_output(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88a90e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# **Plot the Training Loss Curve**\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(iterations, train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(iterations, val_losses, label=\"Validation Loss\", marker='s', linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Progress: Loss vs. Iterations\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the figure (optional)\n",
    "plt.savefig(\"training_progress.png\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06188f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "was wenspesppo shen g briconistrde bo tou, nucke\n",
      "IZed n Haswlenfithambond be askerm Zeabey Jizaly wanend f HNp y s, mey.\n",
      "t.\n",
      "\n",
      "pry ttaggsst tha ITote and-th. fembin re bed: oth othe busu se hol burery fun weroofannd to\n",
      "fl onucthen ce pll.\n",
      "and th.\"HEve.\n",
      "waily soKpeal t we shesheomaccth boror ly.\"S\n",
      "\"heanefia whe frr. bur or\n",
      "t ogy thepondin ime acrermu he an.\n",
      "wacase\n",
      "\" bof meeld, thastoorurd feand Thathothe  S.\n",
      "ngey bovind s\n",
      "l ck; th. traten rer tred touthe.\"Han te oulom aset's ma wat,\" h th?\" ve til\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8da9a6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The h Wh memoulen thes thy be.\n",
      "\n",
      "\"AU6KSTEut po hes larurin y se ld crun or MOUGuthed ute\n",
      "s?\"\n",
      "chirg, w.\n",
      "\n",
      "\n",
      "witf d he\n",
      "sther; of ld ctun tes\n",
      "\n",
      "\n",
      "peaurd heson anthedakery y cayend ery. ad as ary boreth loror thige sou'sed chizeig tira aswizas.\n",
      "[(kspowop, thrdkld mare t tad macecis\n",
      "y t-whed tw iabus, t cewathekanont ther, aks whocremitizaser watoud the bld tronond d ady\n",
      "cun e, Zey Jit' eday ss way\n",
      "\n",
      "e f t wng Eurugotheaty sk-ple in,\"Weredocanerthasiocl Wie ginonons me theaknoyowonilathe th he,  eead t THEm\n"
     ]
    }
   ],
   "source": [
    "# Find the index of 'T' in the embedding table\n",
    "start_index = string_to_int['T']  # Convert 'T' to its corresponding index\n",
    "context = torch.tensor([[start_index]], dtype=torch.long, device=device)\n",
    "generated_chars = decode(model.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fbf16b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
